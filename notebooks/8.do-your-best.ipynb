{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308892a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8fcad",
   "metadata": {},
   "source": [
    "**ESSAYER D'AUTRES CLASSIFICATEURS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a0fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from ift6758.pipeline import ExperimentPipeline, DEFAULT_TRANSFORMATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de6939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificateurs\n",
    "classifiers = {\n",
    "    'k-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'Linear SVC': LinearSVC(),\n",
    "    'SGD': SGDClassifier(),\n",
    "    # excellent avec plus d'itérations, mais trop lent\n",
    "    #'Multi-layer Perceptron': MLPClassifier(max_iter=10, early_stopping=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbb8078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching dataframes from ../data/tabular\n",
      "applying mirror_coordinates\n",
      "applying append_shot_angle\n",
      "applying append_shot_distance\n",
      "applying replace_nan_by_0\n",
      "applying append_game_secs\n",
      "applying append_time_lapse_prev\n",
      "applying append_dist_prev\n",
      "applying append_rebound\n",
      "applying append_angle_change\n",
      "applying append_speed\n",
      "done with preprocessing\n"
     ]
    }
   ],
   "source": [
    "# données\n",
    "df = ExperimentPipeline.get_data('../data/tabular', transformations=DEFAULT_TRANSFORMATIONS)\n",
    "\n",
    "# caractéristiques sélectionnées à l'étape précédente\n",
    "features = ['shot_distance', 'shot_angle', 'dist_prev_event', 'time_lapsed_prev_event_in_seconds', 'game_secs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5561ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "X_nona = X.fillna(0)\n",
    "y = df[['goal']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nona, y)\n",
    "y_train = y_train.squeeze().ravel()\n",
    "y_test  = y_test.squeeze().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bccf05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors\n",
      "0.8960543738790835\n",
      "[[106319   1733]\n",
      " [ 10670    600]]\n",
      "Decision Tree\n",
      "0.8293189856019846\n",
      "[[96868 11184]\n",
      " [ 9182  2088]]\n",
      "Random Forest\n",
      "0.9031276713430885\n",
      "[[107370    682]\n",
      " [ 10877    393]]\n",
      "AdaBoost\n",
      "0.9055413083924172\n",
      "[[107924    128]\n",
      " [ 11143    127]]\n",
      "Naive Bayes\n",
      "0.903496421447847\n",
      "[[107762    290]\n",
      " [ 11225     45]]\n",
      "QDA\n",
      "0.903488040763648\n",
      "[[107760    292]\n",
      " [ 11224     46]]\n",
      "Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9052312230770521\n",
      "[[108005     47]\n",
      " [ 11261      9]]\n",
      "SGD\n",
      "0.9005631819781768\n",
      "[[107237    815]\n",
      " [ 11050    220]]\n"
     ]
    }
   ],
   "source": [
    "for name, model in classifiers.items():\n",
    "    print(name)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred), confusion_matrix(y_test, y_pred), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5e465",
   "metadata": {},
   "source": [
    "**OPTIMISER LES HYPERPARAMÈTRES POUR ADAPTATIVE BOOSTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8de83a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ExperimentPipeline(\n",
    "    tabular_dir='../data/tabular',\n",
    "    feature_columns=features,\n",
    "    target_column='goal',\n",
    "    pipeline_steps=[\n",
    "        ('adaboost', AdaBoostClassifier()),\n",
    "    ],\n",
    "    dataset_transformations=DEFAULT_TRANSFORMATIONS,\n",
    "    parameter_grid=[{\n",
    "        'adaboost__base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)],\n",
    "        'adaboost__n_estimators': [25, 50, 75],\n",
    "        'adaboost__learning_rate': [0.1, 1, 10 ],\n",
    "        \n",
    "    }],\n",
    "    metric='roc_auc',\n",
    "    enable_comet=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb005b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching dataframes from ../data/tabular\n",
      "applying mirror_coordinates\n",
      "applying append_shot_angle\n",
      "applying append_shot_distance\n",
      "applying replace_nan_by_0\n",
      "applying append_game_secs\n",
      "applying append_time_lapse_prev\n",
      "applying append_dist_prev\n",
      "applying append_rebound\n",
      "applying append_angle_change\n",
      "applying append_speed\n",
      "done with preprocessing\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=1), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.1s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.1s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.1s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.1s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.1s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.1s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.1s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=2), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=0.1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=1, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=25;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 2/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 3/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 4/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n",
      "[CV 5/5] END adaboost__base_estimator=DecisionTreeClassifier(max_depth=3), adaboost__learning_rate=10, adaboost__n_estimators=75;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 135 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n135 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 506, in fit\n    return super().fit(X, y, sample_weight)\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 131, in fit\n    X, y = self._validate_data(\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nAdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/IFT6758/notebooks/../ift6758/pipeline/pipeline.py:111\u001b[0m, in \u001b[0;36mExperimentPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m df \u001b[38;5;241m=\u001b[39m ExperimentPipeline\u001b[38;5;241m.\u001b[39mget_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtabular_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformations)\n\u001b[1;32m    110\u001b[0m x_train, y_train, x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_train_test(df)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_comet:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_to_comet()\n",
      "File \u001b[0;32m/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 135 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n135 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 506, in fit\n    return super().fit(X, y, sample_weight)\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 131, in fit\n    X, y = self._validate_data(\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"/mnt/c/Users/valmi dufour-lussier/Documents/MILA/datasci/tpenv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nAdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef0952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
